## Task
1. ~~Try to optimize the min_finder, input_spine_buffer, pass the unit test~~
2. Finish the design of output queue
   1. Design the api (input, output)
   2. Optimize it
   3. Design the unit test for it.
3. Design the filter buffer
   1. Design the api (input, output)
   2. Optimize it
   3. Design the unit test for it.
4. Design the DRAM for it.
5. Integrate the pe, input spine buffer, min_finder, output queue and the DRAM.

#### Input Spine buffer:
1. 16 fixed sized (128) array, with elements: 
struct Entry {
    uint8_t ts;         // timestamp when spike arrives
    uint32_t neuron_id; // which neuron fired
};
from include/common/entry.hpp
2. The function should contain:
   * load from the dram: (base address, size)
   * flush
3. It has communication with min_finder:
   min_finder will only compare the head of 16 input_spine_buffer, and pick the one with the smallest ts, then one element in on input spine buffer is consumed

#### min finder
1. it contains the reference of these 16 input spine buffer
2. The function should contain:
   1. pick up the smallest entry from the input_spine buffer (communication with input spine buffer)
   2. send the Entry (ts, neuron_id) to each PE (communication with PE array)

#### filter buffer
1. Descriptions: 576 KB Filter Buffer organized into 32 banks, with a row width of 128 bytes (providing 128 1-byte weights at a time).In order to feed weights to 128 PEs in a cycle, the Filter
Buffer needs an output bus width of 1024 bits. Depending on the type of layer being executed, bank assignment for weights and feature maps can be configured.
1. The function should contain:
   * load weight from DRAM with address and size.
   * Based on the sent entry from min_finder, pick up the requested row, and send each weight element to each related PE. (communication with min_finder and pe arrays)

#### output queue
1. It should store all the output entries generated by 128 PES, till the pes finish their work. Then it needs to store the whole output queue back to DRAM
2. The functions need to be used:
   1. receive the outputs from the pes (Each time it would be only one output generated by one pe, it is promised by the logic)
   2. check the end of one whole inputs work, after that, store the whole output queue to the DRAM. STORE to should also be: base address, length. And it should convert the data from Entry based to the raw data.

#### Conv-layer
1. Pre-fill the inputs and weight to dram
2. Load weight to filter buffer
3. Conpute the address of the input-dram
4. load the input dram
5. process the output

The layout of the input dram is spine 1(input position [0, 0] across all the input channels), spine 2(input position [0, 1] across all the input channels), spine 100 (input position [9, 9] across all the input channels)
The layout of the filter dram should be [w][h][inC][outC]

Now consider that we have a 5 by 5 filter, the input channel is 512, the output channel is 512, the input image is 100x100, the padding is 0, the stride is 0. 


1. My mind on actually implementing the combination of the input_spine_buffer and the min_finder now is that:

Now we consider a 7 x 7 kernel with 512 input channel. How to make sure it can filter one whole input spine buffer?

The solution here is that: we need to add a logic here:
1. First we need to compute the total cycles we need to get the final input spine:
   * 7 * 7 / (16 - 1) = 3 ... 4, that means we need 4 cycle t
2. In one cycle: The data will be filled in the 15 out of 16 buffers, once the whole buffer is consumed, it will immediately fetch the next 128 data in the spine. The output 


The total logic should be:
For layer from x to xx:
   For output spine from 0 to xx:
      compute the input spine location
      compute how many steps needed for the generation of final input buffer
      send it to input spine buffer
      get the output 


What the input spine needs: the address of each VMEM (loaded for multiple times)
After loaded by all the input spine buffers, run multiple times to get the result


#### The fill in part from CNN layer to input_spine_buffer
1. Batch Scheduling
   * Based on the output spine, the kernel size, the padding and the stride infomation, we can know exactly which spine in the dram needs to be loaded
   * Compute how many batches it is needed
   * make a schedule to link each dram address (logic spine id) with the physical spine id (Above are all from the cpu side)
   * Do a for loop to make the buffer consistantly load the buffer
2. Double-Buffering
3. Intra-batch min-finding
4. 4-way merge
5. PE-computation
6. Output-write back


### The integration of the first part should be:
1. Input: driver::BatchSpineMap or a reference of it:
2. The main process part:
   1. For b in batches:
         For id in physical spine id:
            load data from DRAM
         Process()/Step()

   2. In function Process():
      input spine buffer head and pop head;
      min_finder drainbatchinto;
      IntermediateFIFO front and pop;
      globalMerger pick and pop
3. Output: a list of <Entry>

### filter_buffer_integration
1. Behavior explanation:
   1. Each time loaded one layer of the weight data to the weight buffer(pre-filled)
   2. Each run, receive the neuron-id from the global-merger, decode the neuron-id, find the row to be loaded into 128 PEs, dispatch the data to related PE.
   3. The layout of DRAM should be: [output channels / 128][input channel][size (kh x kw)][0-127]
2. Some assumptions:
   1. for the load data from DRAM, the driver side will also provide a look up table to show the mapping between the physical row id and logical row.
   2. Each row should also store the meta data: neuron id for each row.
   3. once an Entry sent from global merger, it will match the neuron_id with the meta_data of the row, and load the related row to pe.
3. Requirements:
   1. Driver should have a weight lut on the driver (cpu) side/ It is needed to be under driver sub-folder.
      1. The behavior of the sub-folder should be: the map of filter-buffer row id and the neuron-id. 
   2. In conv_layer, they should have the BuildFilterLUT, with ox, oy, kW, kH, inW, inH, strideW, strideH, padW, padH, and the struct of LUT. May be some of the inputs are not needed.
   3. Then integrate the filter buffer into the builder.


### builder
Since the builder is like a hardware part.
1. The input should be the spine map, base address of dram for input, base address of dram for filter (of the whole layer), the configuration of the layer (input channel, input height, input weight, kw, kh, stride, padding, output x, output y, output height, output width)
2. The run function should contain several parts:
   1. pre-fill of input spine buffer and weight buffer(optional, once for one layer)
   2. for loop of step() function:
      1. process the pe
      2. process the global merger and filter row:
         1. the external function (for example BuildFilterLUT in conv_layer will do the mapping between the row id and the neuron id, after finding the row id, we send it to the filter, filter dispatch the row to each pe)
      3. process the intermediate fifo
      4. process the min_finder_batch
      5. process the input spine buffer
      6. Check the necesscity of the dram load
I still don't know why the DramFn function is needed. It is so weird. Could you please explain the necesscity of that part? Otherwise just remove it?
Make the builder clear and with less code. Less comments, but for code itself, make it more humanreadable.
3. Now the previous version of the builder is not working in a hardware way.
   Re-do things like this:
   1. pre-fill of input spine buffer and weight buffer(optional, once for one layer)
   2. for loop of step() function:
      1. process the pe
      2. process the global merger and filter row:
         1. the external function (for example BuildFilterLUT in conv_layer will do the mapping between the row id and the neuron id, after finding the row id, we send it to the filter, filter dispatch the row to each pe)
      3. process the intermediate fifo
      4. process the min_finder_batch
      5. process the input spine buffer
      6. Check the necesscity of the dram load to input spine buffer
   Remove all these three functions like DRAMFN, WEIGHTLOAD, ONEMIT

   one very important part is, for different layers, for example, let's just conside the two cnn layer:
   1. one is input channel 3, output channel 64, kernel size 7 x 7,
      which means each spine contains 3 entries, there are 64 logic spines in the layer, so for processing the intermediate fifo, it needs to wait till at least the first 4 fifos finishing computing. (The condition to use the global merger is that, there must be vaild data for the head of (active but not drained) fifo)
   2. the other layer has input channel 512, kernel 3 x 3, output    channel 512, which means each logical spine contains 512 entries, there are 9 logical spines, and it only needs one fifo (to be activitated), which means there's no stalling in between.
   Previously we designed a map to match the physical addresses with the phyiscal spine buffers. Different batches represent different filled input fifos. However, each fill/re-fill of the 16 physical spines need to be the in the same batch, otherwise we don't know which fifo we need to fill in. So for the first situation, there should be a stall between the stage 3 and stage 2.
   I need to check if it there is feasibility for the hardware implementation.



### latency determination
1. Each time tell the structure of the spinalflow, try to get the appoximate latency.


### DRAM design (Later)
1. DRAM is a high level abstraction in this modeling. It does not need to copy the real dram structure.
2. DRAM will have to main stored data
   1. Input/Output Spine.
   2. Weight.
3. The layout of the weight is like this: [tile_idx = output channel/pe_number][input channel][h][w][pe_number]. Each time the weight access is weight read, one tile upon one time.
4. The layout of the input should be like this: 
   1. Layer l:
      1. spine s: array of Entries <neuron_id, ts>
   The access should be separated into read and write:
      1. Read is for input. Each time it will read one spine of one layer. The spine length is unknown (not fixed).
      2. Write for output. It will write one Entry back to the address based on the layer, spine and tile. Entry is poped from the output queue.
5. For the dram read and write, only once upon a time, cannot be read and written at the same time.
6. It is needed to count the latency of read and write.
7. The dram should keep an empty function for loading real data. (TO DO)



### Conversion:
**Question:** If the input buffer row is 128, then how does the dram layout format look like? And how to figure out the next line?
**Situation:** Consider we have a 512 input channel, 3 by 3 input data, and let's assume each channel will spike 2-3 times throughout the 16 ticks.
               So each Spine will have 1024-1536 spikes. It would be impossible to store all the spine in one run.
**Solution:**  Let's make each row 128 entries. all the spikes can fit in 128 entries, then the next spine will directly follow this entry. If not, after 128 entries, it will also be cut, and switch to the next spines. till all the 9 (3 x 3) spine has been filled once, if there are other spines left, then it will read the spine to input_spine_buffer again.
**Details:** 
1. The data in the dram should have one header, with meta data as below:
   1. matched batch
   2. matched logical spine
   3. matched physical input spine buffer index
   4. size (maximum 128)
   5. if it reaches the end of the logical spine
2. The input spine buffer has 16 physical spine, it also contains the meta data here:
   1. matched batch
   2. matched logical spine
   3. If the whole logical spine is loaded
   4. If the whole logical spine is drained
3. **Notes:** 
   1. Logical spine is the spine which is one position (h, w) in one layer across all the input channels etc. 512. sorted by the time. It supposed to be an array of Entry, which is a pair of time steps and neuron id. Neuron id is encoded by the position, channel index. However, the logical spine in dram can be cut off if it exceeds 128 entries.
   2. Physical spine is the physical input spine buffer, it is a hardware-based concept. It has 128 entries for one buffer, and it has 16 buffers.


### Do the modification here to make it more clear and neat
The main goal of the builder.cpp --> core/clock.cpp is like this: Try to hide the details of the call of each components' function in the stage part, integrate the stage part as "Run()" function in each component, and specify which arguments are needed, and from which component. We can get it from its member: core via the registration of the core to each components. Then in core/clock.cpp, we only need to have one Run() function, which contains all the Run() function from its components.
We do not need to make a brand new core/clock.cpp. We only need to fill in a little bit to which we need to change. The first task is:
1. Integrate the function Stage0_DrainOutputQueue() into output_queue.cpp/hpp, the name of the function is run(). 
2. Add a RegisterCore() function to add the builder/core to the output_queue (as a member). 
3. Leave the latency statistics later. 
4. Leave the builder.cpp/hpp later, change the components first.


### Stage 1 to stage 2 control logic
1. For smallest_ts_picker, each buffer related with one pe's output, it will receive one pe's output. So each time if the control signal is true, it can load all the outputs from stage 2.
2. The control signal is owned by the core, it will only be changed by smallest_ts_picker. If the any outputs from last cycle's stage 2 still not be consumed yet, the the st1_st2_valid will be false, which means stage 2 has to stall. once all the outputs from last step are drained, the st1_st2_valid would set to true, then it is allowed to load the results from the stage 2.

